背景
    研究背景
        深度神经网络模型规模呈现指数级增长
            边缘设备内存容量与模型参数增长之间存在矛盾，需要分布式推理

        边缘云环境的开放和多租户特性性使其面临严峻安全挑战
            恶意租户可以通过侧信道攻击获取敏感数据，不可信基础设施提供商可能故意破坏推理过程完整性

        TEE 技术出现提供了新的技术手段，但是面临内存容量限制
            SGX 2 提供的动态内存特性允许超出有限 EPC 大小，但是导致了频繁换页操作带来巨额开销，每次换页需要进行复杂的加密和完整性验证计算
            SGX 2 提供的动态内存特性允许超出有限 EPC 大小，但是导致了频繁换页操作带来巨额开销，每次换页需要进行复杂的加密和完整性验证计算


    研究现状
    ｜ 缺乏安全性-性能权衡机制不完善
        分布式神经网络推理
            固定分割策略 代表性工作：DNN Surgery & CRA系统
                这两项研究都是将 DNN 模型分割成 2 部分，一部分运行在云端，一部分运行在边缘侧
                Surgery 主要通过图论中的最小割方法
                    【INFOCOM'19】Dynamic Adaptive DNN Surgery for Inference Acceleration on the Edge

                CRA 主要通过马尔可夫链算法获得近似最优解
                    【IEEE Internet of Things Journal'20】Joint DNN Partition Deployment and Resource Allocation for Delay-Sensitive Deep Learning Inference in IoT

                二者都实现了 DNN 模型的静态分割
                弊端在于缺乏对动态环境变化的适应能力，实际应用中性能优化有限

            动态分割技术 逐渐成为焦点
                DADS 系统引入马尔可夫决策
                ｜ 标志着 DNN 分布式推理从静态优化向动态优化的重要转变
                    实现了根据实时网络状况和设备负载动态调整分割点

                DINA 这篇工作 采用了细粒度的 DNN 分割策略与基于游戏匹配策略的算力平衡方法，实现了在端设备实现分割处理，并分发到多个更强算力的节点实现推理加速
                    【INFOCOM'20】Distributed Inference Acceleration with Adaptive DNN Partitioning and Offloading


            研究趋势进一步转向细粒度分割和操作符级并行化
                传统层间分割方法粒度较粗，无法充分利用分布式计算资源的并行性
                DATE'25 HiDP 操作符级的细粒度分割相比传统层间分割实现通信成本降低 20 倍以上，推理延迟减少 65% 以上的显著性能提升
                Galaxy 系统通过创新性的异构感知并行规划和基于瓦片的通信-计算重叠技术，在实际测试中实现了 2.5 倍的端到端延迟减少

            还能做什么：？内存限制对系统性能的影响机制未得到充分的理论分析和技术解决 && 安全性和性能之间的权衡机制不够完善

        可信执行环境技术
            开创性工作： Occlumency
                【MobiCom‘19】Occlumency: Privacy-preserving Remote Deep-learning Inference Using SGX
                通过将 DNN 模型分割为多个部分并在可信执行环境中顺序执行，有效避免了完整模型加载带来的内存压力，核心创新在于将 EPC 内存限制视为硬约束，通过精心设计的分区策略确保每个分区的内存需求不超过 EPC 容量，避免代价高昂的安全页面交换操作
                128 MB for Intel Skylake CPU；Caffe
                AlexNet [50], GoogLeNet [68], ResNet-50/101/152[36], VGG-16/19 [67], and YOLO [63]
                Intel Core i7-7700 (Kabylake) 3.6GHz CPU of 4 cores and 16 GB DDR4 RAM

            Vessels 系统通过优化 DNN 推理过程中的 memory reclaiming 来克服 EPC 大小限制。进一步推进了这一研究方向，通过优化内存回收和垃圾收集机制以提升可信执行环境下的内存利用效率
                【SoCC'20】Vessels: Efficient and Scalable Deep Learning Prediction on Trusted Processors
                设计了针对 DNN 工作负载的内存管理策略，预测性的内存分配和释放显著减少内存碎片化问题

            SECURETF 这篇工作利用了模型简化技术，通过剪枝、量化等技术减少了 DNN 模型的参数量以更好的适应 EPC 大小，提高安全推理的性能
                【Middleware'20】SECURETF: A Secure TensorFlow Framework

            SGX 2 实现了动态内存分配，打破了 SGX 1 中有限内存限制
            ｜ 开辟了优化空间
                普通 Intel 芯片 EPC 容量在 128 MB 到 512 MB 之间；若超出则触发页面交换，页面交换不仅涉及数据的物理迁移，还需要进行复杂的加密和完整性验证，成本是普通页面交换的数百倍。同时， SGX 应用的开发复杂度高，调试困难，需要开发者具备深厚系统安全知识。

            上述工作都将 EPC 大小视为一个硬性限制，并且聚焦于在单个服务器之中执行 DNN 推理以避免过多的内存页面交换
            MEDIA 这篇工作将 DNN 推理场景扩展到 多个服务器的场景，并允许适量的页面交换，以达到页面交换开销与 DNN 模型间通信开销的平衡。
                【ICDCS'22】DNN Partitioning and Assignment for Distributed Inference in SGX Empowered Edge Cloud
                基于 Darknet 该了框架，在 4 台 Intel Celeron G4930 上执行 DNN 推理


        边缘云技术
            ETSI EMC标准化推动边缘云技术不断发展，提供成熟的分布式计算环境



核心创新点
    Motivation:  目前已有的工作已经有关于考虑 SGX Enclave 大小的工作（Occlumency），只是未考虑在多台服务器执行分布式推理的环境下，Vessel 也从推理运行时内存分配的角度缓解 Enclave 大小的问题；MEDIA 进一步将推理扩展到了多个服务器，并综合考虑了 SGX Enclave 的大小，允许适量的页面交换同时综合考虑了通信开销；TAOSIM 也说明了 TSDP 是一个常见的保护模型安全的方法；在分布式 DNN 推理场景下，可以进一步考虑 1. 根据 Enclave 大小分割模型同时考虑通信开销；2. 将敏感的层放入 TEE 中，这其中涉及安全的开销也综合考虑到模型之中。       
        核心思想在于构建 “安全、SGX Enclave 换页、通信 三维耦合的 DNN 分割模型”
        创新性在于前人是“两类人说两类事”——做分布式推理的考虑带宽和通信延迟，做 TEE 的主要考虑 EPC 大小和安全性是否足够。

    创新点一（核心）：构建统一代价 DNN 切割模型：把安全等级、SGX Enclave 动态换页开销、分布式系统通信开销放入一个图模型中综合考虑，对 DNN 模型进行切割。
        这里要做的实验，对比哪个 Baseline，要如何证明这种切割方式是有效保留安全性（安全性的保留要如何证明），并且能够减少推理时间
        输入：DNN RAG/顺序层 + Layer‘s 计算量估计、内存占用大小、安全等级要求
        输出：DNN 的分割结果，每部分对应的执行域（边 TEE / 边 CPU / 云 GPU）

    创新点二（配套，工作量小）安全等级的“自动生成”只做成“规则库 + 少量可解释特征”，而非模型训练结果，使其弱化成为“可插拔标注器”，从而形成基于机密性的多级安全推理架构
        数据敏感性得分：
            规则1：对包含原始敏感信息的早期特征提取层进行标记，区分于高度抽象的中后期层，按照距离输入的距离设计分数递减规则，越近越敏感，得分越高

        模型隐私性得分：
            规则1：对涉及模型核心参数、自定义的关键模型组件进行标记，区分于标准化层、激活函数层
            规则2：

        基于评估结果对创新点 1 中的模型分割结果定义分层安全等级，在不同区域执行
            L 1  (Sdata > SdataThreshold || Smodel > SmodelThreshol 归属于 L1), 严格安全：TEE 内执行
            L 2（）可验证安全：通过密码学证明保护的 TEE 外计算
                具体技术选型是什么？ 比如零知识证明等，这里是创新性的关键体现，需要具体化

            L 3（Else）性能优先：非敏感计算，普通环境执行（CPU || GPU）


    创新点三（动态考虑网络带宽与DNN模型的决策器）安全分布式推理框架
        主要是工程实现：
            监测层：实时采样当前边-云通信的带宽、要执行推理的 DNN 模型
            根据监测层的数据，使用创新点一的模型计算得到分割结果（哪几层共同作为一个模块），使用创新点二的多级安全推理架构确定每个分割结果对应的安全层级，下发分割任务到边和云



实验（证明三个创新点有用）
    主实验
        实验配置：边和云 2 个节点，三种带宽条件（高/中/低），Baseline 模型（）ResNet18, CIFAR-10
        指标：
            端到端推理时延
            传输数据量
            估算/测得的换页次数与换页时间
            模型 L1/L2/L3 的比例

        实验对比对象：
            1. 只考虑通信未考虑安全的分割方法 DNN Surgery，验证考虑安全之后额外开销仅增加了 xxx（较少的额外开销）
            2. 只考虑 EPC 进行切割、完全安全、但是未实现分布式推理的分割方法，如 Occlumency、Vessel，验证实现分布式推理之后，能够实现更快的推理速度
            3. 考虑了 EPC 进行切割、完全安全、实现了分布式推理的分割方法，如 MEDIA，验证实现了多层级安全后，能够有效提高推理速度，同时保留安全性（这点该如何通过实验验证？用一些攻击方式如侧信道对模型推理过程进行攻击？）


    消融实验
        对于创新点 2  消融实验 A：对比不同的安全等级评级策略：
            1.规则版（主实验所采用的）
            2.人工标注版（采用已有工作的标注方法）
            3.不分层（即替换 MEDIA 的分割算法之后的结果）

        对于创新点 3 消融实验 B
            开启 创新点 3 的动态感知功能后：当带宽变化时 => 分割结果会发生变化 => 端到端推理时延曲线比较平滑
            关闭 创新点 3 的动态感知功能后：当带宽变化时 => 分割结果会发生变化 => 端到端推理时延曲线比较陡峭（未考虑到延迟变化使得分割结果不合理）



研究意义（Related Work）
    与过去 Occlumency / Vessels / SecureTF 工作的优化目标主要是围绕着如何在单个服务器 TEE 中让模型推理执行更快且安全；而 ours 的目标是，针对单个模型在多个节点上执行分布式推理场景下、如何安全性进行分级且快速执行推理
        多约束优化理论方面
            传统分布式系统优化主要关注延迟、能耗、精度 3 个维度
            本研究在此基础上引入安全性和内存约束 2 个新的维度
            在这些多个约束之下，如果受不同网络条件、节点负载条件影响之下，算法如何自动适应

        模型分割理论方面
            深入分析 SGX、TrustZone 等架构的内存管理机制
            ｜ 建立考虑 EPC 容量限制、页面交换开销、安全计算成本等因素的精确数学模型

        探索安全性和性能之间的权衡
            建立可信执行环境下安全开销与性能损失的定量关系模型
            ｜ 分析不同安全级别对系统性能的具体影响


    跟 Surgery / CRA / DADS / DINA 的差别：这些工作的优化目标是不考虑安全性（未引入 TEE）的情况下，如何实现更快的 DNN 的分布式推理。
    跟 TAOISM 的区别：TAOISM 认为 TSDP 的安全性被高估了，无法精准选择哪些模型部分需要被保护起来，故而采用先分割再训练的方式，该方法只适用于有限的一些场景

小结：本文针对边缘云场景下的深度神经网络分布式推理，提出一种安全-分页-通信三维耦合的分割优化方法。与现有仅考虑通信开销的分布式分割方案（如 DNN Surgery, CRA）或仅将 EPC 容量视为硬约束的可信推理方案（如 Occlumency, Vessels）不同，本文将 SGX 动态内存分页成本 与 多级安全执行成本（L1/L2/L3） 一并纳入分割代价模型，通过图模型求解获得在给定带宽与内存状态下的最优或近似最优分割。为降低人工配置开销，本文进一步给出一套基于数据敏感性与模型隐私性的规则化安全分层方法，自动为网络各层指定可接受的最低安全级别，作为分割优化的输入。最后，针对边缘云环境中带宽与内存状态的时变性，本文实现了一个轻量级在线重估与分割切换机制，在实际 SGX+GPU 双节点原型上验证了所提方法在端到端时延上的优势。
研究方法
    理论分析方法体系
        运筹学 && 最优化理论经典方法
            引入（内存、安全、性能）等多维约束条件，建立综合考虑性能、安全性和资源利用效率的多目标优化模型
            运用凸优化理论，分析可行域的几何特征、目标函数的凸性质、最优解的存在性和唯一性

        图论分析方法发挥核心作用
            将 DNN 抽象为 DAG，节点表示神经网络层，边表示数据依赖关系，运用图论理论分析模型分割策略；如连通性、割集最小化、图分解等基本概念


    算法设计和优化方法
        经典优化算法
            启发式算法
                针对分割点选择和任务调度等核心问题设计高效的贪心策略，适合实时性要求较高的边缘计算场景

            动态规划方法
            分支定界方法

        现代智能算法
            深度强化学习技术，训练智能调度策略
            遗传算法用于多目标优化问题，Pareto前沿求解
                搜索多目标优化问题的非劣解集

            模拟退火算法
                避免算法陷入局部最优
                    随机搜索和概率接受机制提高算法找全局最优解的能力



        机器学习算法
            聚类分析
                对边缘节点进行能力聚类和任务匹配
                ｜ 相似性度量和聚类算法，实现任务和资源的智能匹配

            时间序列分析
                分析系统性能指标的时变特性，识别系统性能的周期性规律和异常模式




系统实现和验证方法
    基于 TAOISM 框架进行开发
        在此基础上开发模型分割、任务调度、安全执行等核心功能模块

    性能评估
        真实环境
            在 SGX 硬件环境中部署原型系统，通过真实的硬件平台验证系统的实际性能和稳定性，对比推理延迟、系统吞吐量、资源利用率、能耗效率等多个维度的性能指标


    Baseline 模型
        经典卷积网络
            AlexNet、VGG16、Resnet18



研究内容
    深入分析可信执行环境的内存管理机制
        1. EPC 页面的分配和回收策略、2. 页面交换的触发条件和执行过程、3. 内存加密和完整性保护开销；建立精确的可信执行环境内存性能模型
        在此基础上，设计内存感知算法，考虑 计算负载和通信开销最小化，关注内存使用模式的优化；分析不同策略下内存需求模式，预测可能发生的页面交换操作，并将其纳入分割策略的考虑范围。
        ｜ 多层次设计，粗粒度进行初始分割，细粒度进行局部调整，实现计算负载与通信开销之间的最佳平衡；建立数学模型描述分割粒度对系统各项性能指标的影响，包括推理延迟、内存使用效率、通信开销、安全保障水平

    边缘云环境下的安全分布式调度机制
        基于深度强化学习的智能调度策略为系统提供自主学习和决策能力，将边缘云环境抽象为马尔可夫决策过程，定义状态空间、动作空间和奖励函数。通过与环境持续交互，学习最优的调度策略，做出调度决策
        容错和故障恢复机制； 设计多层次容错机制，预防性的负载分散、反应性的故障检测和恢复、适应性的重新调度
        通过负载均衡策略最大化边缘云资源的利用效率；实时监控各个边缘节点的资源使用状况


研究方案实施
    理论建模和分析阶段
        精确测量不同内存使用模式下的性能变化、内存分配和释放开销、页面交换触发条件和执行时间、内存访问的局部性对性能的影响
        建立 内存、安全、性能 约束下的数学优化模型

    算法设计
    系统实现
    实验验证、论文撰写
        实验环境配置、测试用例设计、性能指标定义


