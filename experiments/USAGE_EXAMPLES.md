# ä½¿ç”¨ç¤ºä¾‹å¤§å…¨

## ğŸ¯ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šéªŒè¯ç¯å¢ƒï¼ˆå¿…åšï¼‰

```bash
cd /root/exp_DNN_SGX/TAOISM
python experiments/quick_test.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ“ Imports: PASS
âœ“ Model Creation: PASS
âœ“ LayerProfiler: PASS
âœ“ DataCollector: PASS
```

---

## ğŸ“Š æµ‹é‡ç¤ºä¾‹

### ç¤ºä¾‹2ï¼šæµ‹é‡å•ä¸ªæ¨¡å‹çš„è®¡ç®—å¼€é”€

```bash
# NiNæ¨¡å‹ï¼ŒCPUæ¨¡å¼ï¼Œ10æ¬¡è¿­ä»£ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python experiments/measurement/measure_computation.py \
    --single-model NiN \
    --devices CPU \
    --batch-sizes 1 \
    --iterations 10
```

### ç¤ºä¾‹3ï¼šæµ‹é‡å¤šä¸ªæ¨¡å‹çš„è®¡ç®—å¼€é”€

```bash
# 3ä¸ªæ¨¡å‹ï¼ŒCPUæ¨¡å¼ï¼Œ100æ¬¡è¿­ä»£
python experiments/measurement/measure_computation.py \
    --models NiN ResNet18 AlexNet \
    --devices CPU \
    --batch-sizes 1 \
    --iterations 100
```

### ç¤ºä¾‹4ï¼šæµ‹é‡ä¸åŒæ‰¹å¤§å°çš„å½±å“

```bash
# NiNæ¨¡å‹ï¼Œå¤šä¸ªæ‰¹å¤§å°
python experiments/measurement/measure_computation.py \
    --single-model NiN \
    --devices CPU \
    --batch-sizes 1 4 8 16 \
    --iterations 50
```

### ç¤ºä¾‹5ï¼šæµ‹é‡é€šä¿¡å¼€é”€

```bash
# NiNæ¨¡å‹ï¼Œä¸‰ç§å¸¦å®½æ¡ä»¶
python experiments/measurement/measure_communication.py \
    --single-model NiN \
    --bandwidths 10 100 1000 \
    --iterations 100
```

### ç¤ºä¾‹6ï¼šæµ‹é‡å®‰å…¨å¼€é”€ï¼ˆéœ€è¦SGXï¼‰

```bash
# ç¡®ä¿SGXç¯å¢ƒå·²é…ç½®
source /opt/intel/sgxsdk/environment
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$SGX_SDK/lib64:$LD_LIBRARY_PATH

# è¿è¡Œæµ‹é‡
python experiments/measurement/measure_security.py \
    --models NiN ResNet18 \
    --batch-size 1 \
    --iterations 100
```

### ç¤ºä¾‹7ï¼šæµ‹é‡EPCæ¢é¡µå¼€é”€

```bash
# NiNæ¨¡å‹ï¼Œå¤šä¸ªå†…å­˜å‹åŠ›çº§åˆ«
python experiments/measurement/measure_paging.py \
    --single-model NiN \
    --pressures 50 75 90 100 \
    --iterations 50
```

---

## ğŸ”„ æ‰¹é‡æµ‹è¯•ç¤ºä¾‹

### ç¤ºä¾‹8ï¼šå¿«é€Ÿæ‰¹é‡æµ‹è¯•

```bash
# 2ä¸ªæ¨¡å‹ï¼Œå‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œçº¦10åˆ†é’Ÿ
python experiments/run_all_measurements.py --quick-test
```

### ç¤ºä¾‹9ï¼šå®Œæ•´æ‰¹é‡æµ‹è¯•

```bash
# æ‰€æœ‰6ä¸ªæ¨¡å‹ï¼Œæ ‡å‡†è¿­ä»£æ¬¡æ•°ï¼Œçº¦1-2å°æ—¶
python experiments/run_all_measurements.py --models all
```

### ç¤ºä¾‹10ï¼šé€‰æ‹©æ€§æ‰¹é‡æµ‹è¯•

```bash
# åªæµ‹è¯•3ä¸ªæ¨¡å‹
python experiments/run_all_measurements.py \
    --models NiN ResNet18 AlexNet
```

### ç¤ºä¾‹11ï¼šåŒ…å«æ¢é¡µæµ‹é‡çš„æ‰¹é‡æµ‹è¯•

```bash
# 2ä¸ªè½»é‡æ¨¡å‹ï¼ŒåŒ…å«æ¢é¡µæµ‹é‡
python experiments/run_all_measurements.py \
    --models NiN ResNet18 \
    --include-paging
```

---

## ğŸ“ˆ æ•°æ®åˆ†æç¤ºä¾‹

### ç¤ºä¾‹12ï¼šåˆ†æå•ä¸ªæ¨¡å‹

```bash
# åˆ†æNiNçš„æ‰€æœ‰æµ‹é‡ç»“æœ
python experiments/analyze_results.py --model NiN --type all
```

### ç¤ºä¾‹13ï¼šåˆ†æç‰¹å®šç±»å‹

```bash
# åªåˆ†æè®¡ç®—å¼€é”€
python experiments/analyze_results.py --model NiN --type computation

# åªåˆ†æé€šä¿¡å¼€é”€
python experiments/analyze_results.py --model VGG16 --type communication

# åªåˆ†æå®‰å…¨å¼€é”€
python experiments/analyze_results.py --model ResNet18 --type security
```

### ç¤ºä¾‹14ï¼šæŸ¥çœ‹å¯ç”¨æ•°æ®

```bash
python experiments/analyze_results.py --list
```

### ç¤ºä¾‹15ï¼šæ‰¹é‡åˆ†ææ‰€æœ‰æ¨¡å‹

```bash
# ä¸ºæ‰€æœ‰æ¨¡å‹ç”Ÿæˆå›¾è¡¨
for model in NiN ResNet18 AlexNet VGG16 InceptionV3 InceptionV4; do
    echo "Analyzing $model..."
    python experiments/analyze_results.py --model $model --type all
done

# æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨
ls -lh experiments/figures/
```

---

## ğŸ”§ é«˜çº§ç”¨æ³•ç¤ºä¾‹

### ç¤ºä¾‹16ï¼šè‡ªå®šä¹‰è¿­ä»£æ¬¡æ•°

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆ10æ¬¡è¿­ä»£ï¼‰
python experiments/measurement/measure_computation.py \
    --single-model NiN --devices CPU --iterations 10

# æ ‡å‡†æµ‹è¯•ï¼ˆ100æ¬¡è¿­ä»£ï¼‰
python experiments/measurement/measure_computation.py \
    --single-model NiN --devices CPU --iterations 100

# é«˜ç²¾åº¦æµ‹è¯•ï¼ˆ1000æ¬¡è¿­ä»£ï¼‰
python experiments/measurement/measure_computation.py \
    --single-model NiN --devices CPU --iterations 1000
```

### ç¤ºä¾‹17ï¼šåªæµ‹é‡ç‰¹å®šå±‚

ç¼–è¾‘Pythonä»£ç ï¼Œæ·»åŠ å±‚è¿‡æ»¤ï¼š

```python
# åœ¨ layer_profiler.py ä¸­
def profile_all_layers(self, batch_size=1, num_iterations=100, layer_indices=None):
    results = []
    for idx, layer in enumerate(self.model.layers):
        if layer_indices is None or idx in layer_indices:
            result = self.profile_single_layer(layer, idx, batch_size, num_iterations)
            if result is not None:
                results.append(result)
    return results
```

ä½¿ç”¨ï¼š
```python
# åªæµ‹é‡å‰5å±‚
profiler.profile_all_layers(layer_indices=[0, 1, 2, 3, 4])
```

### ç¤ºä¾‹18ï¼šå¯¼å‡ºCSVæ ¼å¼

```python
# å°†JSONæ•°æ®è½¬æ¢ä¸ºCSV
import json
import csv

# è¯»å–JSON
with open('experiments/data/computation_cost_NiN_CPU.json') as f:
    data = json.load(f)

# å†™å…¥CSV
with open('nin_results.csv', 'w', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=['layer_name', 'mean_ms', 'param_count'])
    writer.writeheader()
    for layer in data.get('layers', []):
        writer.writerow({
            'layer_name': layer['name'],
            'mean_ms': layer['mean_ms'],
            'param_count': layer['param_count']
        })
```

---

## ğŸ› æ•…éšœæ’æŸ¥ç¤ºä¾‹

### ç¤ºä¾‹19ï¼šå¤„ç†Importé”™è¯¯

```bash
# é—®é¢˜ï¼šModuleNotFoundError
# è§£å†³ï¼šç¡®ä¿åœ¨æ­£ç¡®ç›®å½•å¹¶è®¾ç½®è·¯å¾„

cd /root/exp_DNN_SGX/TAOISM
export PYTHONPATH=/root/exp_DNN_SGX/TAOISM:$PYTHONPATH
python experiments/quick_test.py
```

### ç¤ºä¾‹20ï¼šå¤„ç†Enclaveåˆå§‹åŒ–å¤±è´¥

```bash
# æ£€æŸ¥SGXçŠ¶æ€
bash scripts/check_sgx2_edmm.sh

# å¦‚æœSGXä¸å¯ç”¨ï¼Œå…ˆç”¨CPUæ¨¡å¼
python experiments/measurement/measure_computation.py \
    --single-model NiN --devices CPU
```

### ç¤ºä¾‹21ï¼šå¤„ç†å†…å­˜ä¸è¶³

```bash
# æ–¹æ¡ˆ1ï¼šå‡å°æ‰¹å¤§å°
python experiments/measurement/measure_computation.py \
    --single-model VGG16 --batch-sizes 1

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨æ›´å°çš„æ¨¡å‹
python experiments/measurement/measure_computation.py \
    --models NiN ResNet18  # è€Œä¸æ˜¯VGG16

# æ–¹æ¡ˆ3ï¼šè°ƒæ•´chunké…ç½®å¹¶é‡æ–°ç¼–è¯‘
# ç¼–è¾‘ Include/common_with_enclaves.h
# å‡å° STORE_CHUNK_ELEM
# ç„¶å: make clean && make
```

---

## ğŸ“Š æ•°æ®ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹22ï¼šæå–æˆæœ¬æ¨¡å‹å‚æ•°

```python
import json
import numpy as np
from sklearn.linear_model import LinearRegression

# è¯»å–æ•°æ®
with open('experiments/data/computation_cost_NiN_CPU.json') as f:
    data = json.load(f)

# æå–ç‰¹å¾å’Œæ ‡ç­¾
X = []  # [param_count, input_size]
y = []  # time_ms

for layer in data.get('layers', []):
    if layer['param_count'] > 0:  # æœ‰å‚æ•°çš„å±‚
        X.append([layer['param_count'], layer.get('memory_mb', 0)])
        y.append(layer['mean_ms'])

X = np.array(X)
y = np.array(y)

# æ‹Ÿåˆçº¿æ€§æ¨¡å‹
model = LinearRegression()
model.fit(X, y)

print(f"è®¡ç®—æˆæœ¬æ¨¡å‹: T = {model.coef_[0]:.6f} * params + {model.coef_[1]:.6f} * memory + {model.intercept_:.6f}")
print(f"RÂ²: {model.score(X, y):.4f}")
```

### ç¤ºä¾‹23ï¼šç”Ÿæˆè®ºæ–‡è¡¨æ ¼

```python
import json
import pandas as pd

# æ”¶é›†æ‰€æœ‰æ¨¡å‹æ•°æ®
models = ['NiN', 'ResNet18', 'AlexNet', 'VGG16']
table_data = []

for model in models:
    filename = f'experiments/data/computation_cost_{model}_aggregated.json'
    with open(filename) as f:
        data = json.load(f)
    
    cpu_data = data['devices']['CPU']['batch_1']
    summary = cpu_data['summary']
    
    table_data.append({
        'Model': model,
        'Layers': summary['total_layers'],
        'Params (M)': summary['total_params'] / 1e6,
        'Memory (MB)': summary['total_memory_mb'],
        'Time (ms)': summary['total_time_ms']
    })

# åˆ›å»ºè¡¨æ ¼
df = pd.DataFrame(table_data)
print(df.to_markdown(index=False))

# ä¿å­˜ä¸ºCSV
df.to_csv('model_comparison.csv', index=False)
```

### ç¤ºä¾‹24ï¼šç»˜åˆ¶è‡ªå®šä¹‰å›¾è¡¨

```python
import json
import matplotlib.pyplot as plt

# è¯»å–å¤šä¸ªæ¨¡å‹çš„æ•°æ®
models = ['NiN', 'ResNet18', 'AlexNet']
times = []
params = []

for model in models:
    with open(f'experiments/data/computation_cost_{model}_CPU.json') as f:
        data = json.load(f)
    
    summary = data.get('summary', {})
    times.append(summary['total_time_ms'])
    params.append(summary['total_params'] / 1e6)

# ç»˜å›¾
plt.figure(figsize=(10, 6))
plt.scatter(params, times, s=100, alpha=0.6)

for i, model in enumerate(models):
    plt.annotate(model, (params[i], times[i]), 
                xytext=(5, 5), textcoords='offset points')

plt.xlabel('Parameters (Million)')
plt.ylabel('Inference Time (ms)')
plt.title('Model Size vs Inference Time')
plt.grid(True, alpha=0.3)
plt.savefig('custom_plot.png', dpi=300, bbox_inches='tight')
print("å›¾è¡¨å·²ä¿å­˜: custom_plot.png")
```

---

## ğŸ“ è®ºæ–‡å†™ä½œç¤ºä¾‹

### ç¤ºä¾‹25ï¼šå¼•ç”¨å®éªŒæ•°æ®

```latex
% LaTeXè®ºæ–‡ç¤ºä¾‹

\section{å®éªŒè¯„ä¼°}

\subsection{å®éªŒè®¾ç½®}

æœ¬æ–‡åŸºäºTAOISMæ¡†æ¶å®ç°äº†å®Œæ•´çš„æµ‹é‡ç³»ç»Ÿï¼Œæµ‹è¯•äº†6ä¸ªä»£è¡¨æ€§DNNæ¨¡å‹ï¼š
NiNã€ResNet18ã€AlexNetã€VGG16ã€Inception V3å’ŒInception V4ã€‚
æ¯ä¸ªæ¨¡å‹è¿›è¡Œ100æ¬¡æ¨ç†æµ‹é‡ï¼Œå–å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆç»“æœã€‚

\subsection{è®¡ç®—å¼€é”€}

è¡¨\ref{tab:computation}å±•ç¤ºäº†å„æ¨¡å‹åœ¨CPUå’ŒSGX Enclaveä¸­çš„æ¨ç†æ—¶é—´å¯¹æ¯”ã€‚

\begin{table}[h]
\centering
\caption{å„æ¨¡å‹è®¡ç®—å¼€é”€å¯¹æ¯”}
\label{tab:computation}
\begin{tabular}{lrrr}
\hline
æ¨¡å‹ & å‚æ•°é‡(M) & CPU(ms) & Enclave(ms) \\
\hline
NiN      & 1.0  & 45.2  & 58.7  \\
ResNet18 & 11.2 & 123.5 & 156.3 \\
AlexNet  & 60.0 & 234.1 & 298.4 \\
VGG16    & 138.4& 456.7 & 587.2 \\
\hline
\end{tabular}
\end{table}

% æ•°æ®æ¥æº: experiments/data/computation_cost_*_aggregated.json
```

### ç¤ºä¾‹26ï¼šå¼•ç”¨å›¾è¡¨

```latex
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/NiN_computation_layerwise.png}
\caption{NiNæ¨¡å‹å±‚çº§è®¡ç®—æ—¶é—´åˆ†å¸ƒ}
\label{fig:nin_computation}
\end{figure}

% å›¾è¡¨æ¥æº: python experiments/analyze_results.py --model NiN --type computation
```

---

## ğŸ”¬ ç ”ç©¶åˆ†æç¤ºä¾‹

### ç¤ºä¾‹27ï¼šåˆ†æå®‰å…¨å¼€é”€è¶‹åŠ¿

```python
import json
import numpy as np

models = ['NiN', 'ResNet18', 'AlexNet', 'VGG16']
overhead_percents = []

for model in models:
    with open(f'experiments/data/security_cost_{model}.json') as f:
        data = json.load(f)
    
    overhead = data['summary']['total_overhead_percent']
    overhead_percents.append(overhead)
    print(f"{model}: {overhead:.1f}% security overhead")

avg_overhead = np.mean(overhead_percents)
print(f"\nå¹³å‡å®‰å…¨å¼€é”€: {avg_overhead:.1f}%")
print(f"ç»“è®º: TEEæ‰§è¡Œå¹³å‡å¢åŠ çº¦{avg_overhead:.0f}%çš„æ—¶é—´å¼€é”€")
```

### ç¤ºä¾‹28ï¼šåˆ†æå¸¦å®½-å»¶è¿Ÿå…³ç³»

```python
import json
import matplotlib.pyplot as plt

# è¯»å–é€šä¿¡å¼€é”€æ•°æ®
with open('experiments/data/communication_cost_NiN.json') as f:
    data = json.load(f)

# æå–å¸¦å®½å’Œå»¶è¿Ÿ
bandwidths = data['bandwidths_mbps']
total_costs = []

for bw in bandwidths:
    cost = data['summary']['total_comm_cost'][f'{bw}Mbps']
    total_costs.append(cost)

# ç»˜å›¾
plt.figure(figsize=(8, 6))
plt.plot(bandwidths, total_costs, 'o-', linewidth=2, markersize=8)
plt.xlabel('Bandwidth (Mbps)')
plt.ylabel('Communication Cost (ms)')
plt.title('Bandwidth vs Communication Latency')
plt.xscale('log')
plt.grid(True, alpha=0.3)
plt.savefig('bandwidth_latency.png', dpi=300)

# æ‹Ÿåˆæ¨¡å‹
# T_comm = a + b/BW
from scipy.optimize import curve_fit

def comm_model(bw, a, b):
    return a + b / bw

params, _ = curve_fit(comm_model, bandwidths, total_costs)
print(f"é€šä¿¡æˆæœ¬æ¨¡å‹: T_comm = {params[0]:.2f} + {params[1]:.2f}/BW")
```

---

## ğŸ› ï¸ æ‰©å±•å¼€å‘ç¤ºä¾‹

### ç¤ºä¾‹29ï¼šæ·»åŠ æ–°çš„æµ‹é‡æŒ‡æ ‡

```python
# åœ¨ layer_profiler.py ä¸­æ·»åŠ æ–°æŒ‡æ ‡

class LayerProfiler:
    def benchmark_layer(self, layer, input_tensor, num_iterations=100, warmup=10):
        times = []
        memory_usage = []  # æ–°å¢ï¼šå†…å­˜ä½¿ç”¨è®°å½•
        
        for _ in range(num_iterations):
            start = time.perf_counter()
            
            # è®°å½•å†…å­˜ä½¿ç”¨
            if torch.cuda.is_available():
                mem_before = torch.cuda.memory_allocated()
            
            output = layer.forward(input_tensor)
            
            if torch.cuda.is_available():
                mem_after = torch.cuda.memory_allocated()
                memory_usage.append(mem_after - mem_before)
            
            elapsed = (time.perf_counter() - start) * 1000
            times.append(elapsed)
        
        return {
            'mean_ms': float(np.mean(times)),
            # ... å…¶ä»–ç»Ÿè®¡ ...
            'avg_memory_mb': float(np.mean(memory_usage)) / (1024*1024) if memory_usage else 0,
        }
```

### ç¤ºä¾‹30ï¼šæ·»åŠ æ–°æ¨¡å‹

```python
# experiments/models/my_custom_model.py

import sys
sys.path.insert(0, '.')

from python.layers.sgx_conv_base import SGXConvBase
from python.layers.sgx_linear_base import SGXLinearBase
# ... å…¶ä»–imports

class SGXMyCustomModel:
    def __init__(self, sid=0, num_classes=10, 
                 enclave_mode=ExecutionModeOptions.Enclave):
        self.layers = self._build_network()
        self.model_name = 'MyCustomModel'
    
    def _build_network(self):
        layers = []
        # å®šä¹‰æ‚¨çš„æ¨¡å‹ç»“æ„
        # ...
        return layers

# ç„¶ååœ¨ models/__init__.py ä¸­æ³¨å†Œ
# from .my_custom_model import SGXMyCustomModel
# __all__.append('SGXMyCustomModel')

# åœ¨æµ‹é‡è„šæœ¬ä¸­æ·»åŠ 
# MODEL_REGISTRY['MyCustomModel'] = SGXMyCustomModel
```

---

## ğŸ“ è®ºæ–‡æ•°æ®å‡†å¤‡ç¤ºä¾‹

### ç¤ºä¾‹31ï¼šå‡†å¤‡è¡¨æ ¼æ•°æ®

```bash
# æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„å®Œæ•´æ•°æ®
python experiments/run_all_measurements.py --models all

# æå–ä¸ºExcelå‹å¥½æ ¼å¼
python << 'EOF'
import json
import pandas as pd

models = ['NiN', 'ResNet18', 'AlexNet', 'VGG16', 'InceptionV3', 'InceptionV4']
results = []

for model in models:
    # è®¡ç®—å¼€é”€
    with open(f'experiments/data/computation_cost_{model}_aggregated.json') as f:
        comp = json.load(f)
    cpu_time = comp['devices']['CPU']['batch_1']['summary']['total_time_ms']
    
    # é€šä¿¡å¼€é”€
    with open(f'experiments/data/communication_cost_{model}.json') as f:
        comm = json.load(f)
    comm_100mbps = comm['summary']['total_comm_cost']['100Mbps']
    
    results.append({
        'Model': model,
        'CPU Time (ms)': cpu_time,
        'Comm 100Mbps (ms)': comm_100mbps,
        'Total (ms)': cpu_time + comm_100mbps
    })

df = pd.DataFrame(results)
df.to_csv('paper_table_data.csv', index=False)
df.to_excel('paper_table_data.xlsx', index=False)
print("æ•°æ®å·²å¯¼å‡ºåˆ° paper_table_data.csv/xlsx")
EOF
```

### ç¤ºä¾‹32ï¼šå‡†å¤‡å›¾è¡¨æ•°æ®

```bash
# ç”Ÿæˆæ‰€æœ‰è®ºæ–‡æ‰€éœ€å›¾è¡¨
for model in NiN ResNet18 AlexNet VGG16 InceptionV3 InceptionV4; do
    python experiments/analyze_results.py --model $model --type all
done

# æ•´ç†å›¾è¡¨
mkdir -p paper_figures
cp experiments/figures/*.png paper_figures/

echo "å›¾è¡¨å·²å¤åˆ¶åˆ° paper_figures/"
ls -lh paper_figures/
```

---

## ğŸ¯ å®Œæ•´å®éªŒæµç¨‹ç¤ºä¾‹

### ç¤ºä¾‹33ï¼šä»é›¶åˆ°å®Œæˆçš„å®Œæ•´æµç¨‹

```bash
#!/bin/bash
# å®Œæ•´å®éªŒæµç¨‹

# 1. ç¯å¢ƒéªŒè¯
echo "Step 1: éªŒè¯ç¯å¢ƒ"
python experiments/quick_test.py

# 2. æ”¶é›†è®¡ç®—å¼€é”€æ•°æ®
echo "Step 2: æµ‹é‡è®¡ç®—å¼€é”€"
python experiments/measurement/measure_computation.py \
    --models NiN ResNet18 AlexNet \
    --devices CPU \
    --batch-sizes 1 4 8 \
    --iterations 100

# 3. æ”¶é›†é€šä¿¡å¼€é”€æ•°æ®
echo "Step 3: æµ‹é‡é€šä¿¡å¼€é”€"
python experiments/measurement/measure_communication.py \
    --models NiN ResNet18 AlexNet \
    --bandwidths 10 100 1000 \
    --iterations 100

# 4. æ”¶é›†å®‰å…¨å¼€é”€æ•°æ®
echo "Step 4: æµ‹é‡å®‰å…¨å¼€é”€"
python experiments/measurement/measure_security.py \
    --models NiN ResNet18 \
    --iterations 100

# 5. ç”Ÿæˆå›¾è¡¨
echo "Step 5: ç”Ÿæˆå›¾è¡¨"
for model in NiN ResNet18 AlexNet; do
    python experiments/analyze_results.py --model $model --type all
done

# 6. æ•´ç†ç»“æœ
echo "Step 6: æ•´ç†ç»“æœ"
mkdir -p final_results/{data,figures}
cp experiments/data/*.json final_results/data/
cp experiments/figures/*.png final_results/figures/

echo "å®Œæˆï¼ç»“æœä¿å­˜åœ¨ final_results/"
```

---

## ğŸ å®ç”¨æŠ€å·§

### æŠ€å·§1ï¼šå¹¶è¡Œæµ‹è¯•å¤šä¸ªæ¨¡å‹

```bash
# ä½¿ç”¨GNU parallelæˆ–åå°ä»»åŠ¡
python experiments/measurement/measure_computation.py --single-model NiN &
python experiments/measurement/measure_computation.py --single-model ResNet18 &
wait
echo "ä¸¤ä¸ªæ¨¡å‹æµ‹è¯•å®Œæˆ"
```

### æŠ€å·§2ï¼šå®šæ—¶è¿è¡Œé•¿æ—¶é—´æµ‹è¯•

```bash
# ä½¿ç”¨nohupåœ¨åå°è¿è¡Œ
nohup python experiments/run_all_measurements.py --models all > output.log 2>&1 &

# æŸ¥çœ‹è¿›åº¦
tail -f output.log
```

### æŠ€å·§3ï¼šå¿«é€Ÿæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹

```bash
# ä¸€è¡Œå‘½ä»¤å¯¹æ¯”
python << 'EOF'
import json

models = ['NiN', 'ResNet18']
for m in models:
    with open(f'experiments/data/computation_cost_{m}_CPU.json') as f:
        data = json.load(f)
    time = sum(l['mean_ms'] for l in data['layers'])
    print(f"{m}: {time:.2f}ms")
EOF
```

---

**æç¤º**ï¼šæ›´å¤šç¤ºä¾‹è¯·å‚è€ƒå„æµ‹é‡è„šæœ¬çš„ `--help` è¾“å‡ºã€‚

```bash
python experiments/measurement/measure_computation.py --help
python experiments/measurement/measure_communication.py --help
python experiments/measurement/measure_security.py --help
python experiments/measurement/measure_paging.py --help
python experiments/run_all_measurements.py --help
```

